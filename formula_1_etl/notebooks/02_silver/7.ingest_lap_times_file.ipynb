{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "1d086d17-8f9f-4c81-8473-1e56668cbad9",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "### Ingest lap_times folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "eb0e606c-f93e-480a-ada1-8e01a700e513",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/ricardo/Documentos/Projects/dab-ci-cd/dab_project/.venv/lib/python3.12/site-packages/databricks/sdk/_widgets/__init__.py:71: UserWarning: \n",
                        "To use databricks widgets interactively in your notebook, please install databricks sdk using:\n",
                        "\tpip install 'databricks-sdk[notebook]'\n",
                        "Falling back to default_value_only implementation for databricks widgets.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "dbutils.widgets.text(\"p_data_source\", \"\")\n",
                "v_data_source = dbutils.widgets.get(\"p_data_source\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "e2ca5b5f-08fc-448a-9235-b2efc86a78b7",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from formula1.formula1_constants import raw_folder_path, processed_folder_path, presentation_folder_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "dde21d5d-33a4-485e-ad34-29ee8ba6a595",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from formula1.formula1_utils import add_ingestion_date, re_arrange_partition_column, df_column_to_list"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "c10a9b41-e54b-4be3-9579-680b36628fdb",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "##### Step 1 - Read the CSV file using the spark dataframe reader API"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "e96f6f6e-23b4-400b-a056-1a6acb01c9ab",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "c3a4491a-b952-4196-969b-bf5c7965b4b0",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "lap_times_schema = StructType(fields=[StructField(\"raceId\", IntegerType(), False),\n",
                "                                      StructField(\"driverId\", IntegerType(), True),\n",
                "                                      StructField(\"lap\", IntegerType(), True),\n",
                "                                      StructField(\"position\", IntegerType(), True),\n",
                "                                      StructField(\"time\", StringType(), True),\n",
                "                                      StructField(\"milliseconds\", IntegerType(), True)\n",
                "                                     ])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "03a2f953-b4a0-46f0-880e-ed3bfd3b1b1a",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "lap_times_df = spark.read \\\n",
                ".schema(lap_times_schema) \\\n",
                ".csv(f\"{raw_folder_path}/lap_times\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "11a12637-558c-4342-8375-821d65060739",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "##### Step 2 - Rename columns and add new columns\n",
                "1. Rename driverId and raceId\n",
                "1. Add ingestion_date with current timestamp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "03cb7b0b-f159-423d-8e7c-e44bbdb367d5",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "lap_times_with_ingestion_date_df = add_ingestion_date(lap_times_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "dabce6bd-f30c-4206-849a-abd21eeb5abf",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "from pyspark.sql.functions import lit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "3f9f833e-aee5-47df-b553-da43dbefc16b",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "final_df = lap_times_with_ingestion_date_df.withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
                ".withColumnRenamed(\"raceId\", \"race_id\") \\\n",
                ".withColumn(\"data_source\", lit(v_data_source))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "2322063f-9693-4033-b70d-df6091c05224",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "source": [
                "##### Step 3 - Write to output to processed container in parquet format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "b352a725-a812-4941-8aec-3d6f3c631b63",
                    "showTitle": false,
                    "tableResultSettingsMap": {},
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "final_df.write.mode(\"overwrite\").parquet(f\"{processed_folder_path}/lap_times\")"
            ]
        }
    ],
    "metadata": {
        "application/vnd.databricks.v1+notebook": {
            "computePreferences": null,
            "dashboards": [],
            "environmentMetadata": null,
            "inputWidgetPreferences": null,
            "language": "python",
            "notebookMetadata": {
                "pythonIndentUnit": 2
            },
            "notebookName": "7.ingest_lap_times_file",
            "widgets": {
                "p_data_source": {
                    "currentValue": "",
                    "nuid": "81fd657c-dcc2-485a-afda-409b05f04266",
                    "typedWidgetInfo": null,
                    "widgetInfo": {
                        "defaultValue": "",
                        "label": null,
                        "name": "p_data_source",
                        "options": {
                            "autoCreated": null,
                            "validationRegex": null,
                            "widgetType": "text"
                        },
                        "widgetType": "text"
                    }
                }
            }
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
